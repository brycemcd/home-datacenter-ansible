---
#- hosts: hadoop-boxes
- hosts: new-hadoop-boxes
  user: hduser
  tasks:
    - name: Make sure spark3's key is in authorized_keys
      lineinfile: dest=.ssh/authorized_keys line="ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDQNRr+/VmaNb6esWnezMDG9WaEZpfpQDkRiHqf4sXpKf3RWCdmRMgqh2oW5rD69srGm7y4LM5j0tMOfYc9L1nwQ+Y/shIWC8uIvtVz/SdngWLJsxOgMn4b6Qpaw2SeICxnTuQAx7qa+QZJvmph2gGXAYtNlvUTRXxWhDcPVmfTcsokBUNu5LzKSM6gVNUDm0U8R5+s1LB0pPjr8oOZ95YSHiDR91cn4tV5VG95UfeSeY9JOPDXi8QdXQAofn0f84zhUIsUxuoQVqOfbjr19vHa+VlGokZho56rC/vHun28mxO9OQbQqQ092rJA7r1r5kz1Rf8drZyTNsJSol25pEwp hduser@spark3"

- hosts: new-hadoop-boxes
  user: brycemcd
  sudo: yes
  vars:
    local_hadoop_template_path: ../../templates/hadoop
    hadoop_install_path: /usr/local/hadoop-2.6.2
    hadoop_slave_internal_hosts:
      - {hostname: spark1.thedevranch.net, ip: 10.1.2.235}
      - {hostname: spark2.thedevranch.net, ip: 10.1.2.234}
      - {hostname: spark3.thedevranch.net, ip: 10.1.2.244}
      - {hostname: spark4.thedevranch.net, ip: 10.1.2.230}
  tasks:
    - name: remove existing download if exists
      shell: rm -rf hadoop-2.6.2.tar.gz*
      ignore_errors: True

    - name: remove any untarred but unmoved versions too
      command: rm -rf hadoop-2.6.2
      ignore_errors: True

    - name: download hadoop
      command: wget http://apache.mirrors.lucidnetworks.net/hadoop/common/hadoop-2.6.2/hadoop-2.6.2.tar.gz

    - name: untar hadoop
      command: tar zxvf hadoop-2.6.2.tar.gz

    - name: remove anything that might be there
      command: rm -rf {{hadoop_install_path}}
      ignore_errors: True

    - name: move hadoop
      command: mv hadoop-2.6.2 /usr/local/

    - name: perms!
      file: path=/usr/local/hadoop-2.6.2 state=directory mode=775 owner=hduser group=hadoop

    - template: src={{local_hadoop_template_path}}/hadoop-env.sh
        dest={{hadoop_install_path}}/etc/hadoop/hadoop-env.sh
        mode=0664
        owner=hduser
    - template: src={{local_hadoop_template_path}}/core-site.xml
        dest={{hadoop_install_path}}/etc/hadoop/core-site.xml
        mode=0664
        owner=hduser
    - template: src={{local_hadoop_template_path}}/mapred-site.xml
        dest={{hadoop_install_path}}/etc/hadoop/mapred-site.xml
        mode=0664
        owner=hduser
    - template: src={{local_hadoop_template_path}}/yarn-site.xml
        dest={{hadoop_install_path}}/etc/hadoop/yarn-site.xml
        mode=0664
        owner=hduser

    - name: Really important! remove any existing directories
      command: rm -rf /usr/local/hadoop_store

    - file: path=/usr/local/hadoop_store/hdfs/namenode state=directory mode=0775 owner=hduser group=hadoop
    - file: path=/usr/local/hadoop_store/hdfs/datanode state=directory mode=0775 owner=hduser group=hadoop

    - template: src={{local_hadoop_template_path}}/hdfs-site.xml
        dest={{hadoop_install_path}}/etc/hadoop/hdfs-site.xml
        mode=0664
        owner=hduser

    - name: create hadoop masters
      template: src={{local_hadoop_template_path}}/etc_hadoop_master
        dest={{hadoop_install_path}}/etc/hadoop/masters
        mode=0664
        owner=hduser

    - name: install hadoop slaves file
      file: path={{hadoop_install_path}}/etc/hadoop/slaves state=touch mode=755 owner=hduser group=hadoop

    - name: add hosts to file
      lineinfile: dest={{hadoop_install_path}}/etc/hadoop/slaves line={{item.hostname}} state=present
      with_items:
        - "{{hadoop_slave_internal_hosts}}"

    - name: add hosts to etc hosts <-- causes many bugs if not!
      lineinfile: dest=/etc/hosts line="{{item.ip}} {{item.hostname}}" state=present
      with_items:
        - "{{hadoop_slave_internal_hosts}}"
        - {hostname: hdfs-master.thedevranch.net, ip: 10.1.2.244}

    - name: Format the namenode
      # NOTE: DELETES DATA!!
      shell: "{{hadoop_install_path}}/bin/hadoop namenode -format -nonInteractive -force"
      args:
        executable: /bin/bash
      sudo: no
      remote_user: hduser


